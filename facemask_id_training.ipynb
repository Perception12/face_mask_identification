{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb55051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5942aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directory and categories\n",
    "DIRECTORY = r\"C:\\Users\\HP\\Desktop\\projects\\face_mask_detector\\dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448f76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, number of epochs to train for,and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827bfe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e6055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:979: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        imgPath = os.path.join(path, img)\n",
    "        image = load_img(imgPath, target_size=(224,224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        \n",
    "        data.append(image)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09880bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e33f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8772da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf0ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the training image generator for data augmentation\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "rotation_range=20,\n",
    "zoom_range=0.15,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.15,\n",
    "horizontal_flip=True,\n",
    "fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c36fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc34f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV2\n",
    "\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, \n",
    "                        input_tensor=Input(shape=(224,224,3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc768cfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102/102 [==============================] - 334s 3s/step - loss: 0.3880 - accuracy: 0.8600 - val_loss: 0.1341 - val_accuracy: 0.9829\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 333s 3s/step - loss: 0.1451 - accuracy: 0.9658 - val_loss: 0.0751 - val_accuracy: 0.9853\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 328s 3s/step - loss: 0.1015 - accuracy: 0.9723 - val_loss: 0.0579 - val_accuracy: 0.9890\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 344s 3s/step - loss: 0.0819 - accuracy: 0.9763 - val_loss: 0.0523 - val_accuracy: 0.9878\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 350s 3s/step - loss: 0.0688 - accuracy: 0.9809 - val_loss: 0.0465 - val_accuracy: 0.9902\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 371s 4s/step - loss: 0.0567 - accuracy: 0.9846 - val_loss: 0.0445 - val_accuracy: 0.9878\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 437s 4s/step - loss: 0.0537 - accuracy: 0.9849 - val_loss: 0.0456 - val_accuracy: 0.9878\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 438s 4s/step - loss: 0.0520 - accuracy: 0.9846 - val_loss: 0.0436 - val_accuracy: 0.9878\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 440s 4s/step - loss: 0.0452 - accuracy: 0.9883 - val_loss: 0.0449 - val_accuracy: 0.9866\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 507s 5s/step - loss: 0.0438 - accuracy: 0.9886 - val_loss: 0.0378 - val_accuracy: 0.9890\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 541s 5s/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.0381 - val_accuracy: 0.9878\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 561s 5s/step - loss: 0.0373 - accuracy: 0.9895 - val_loss: 0.0379 - val_accuracy: 0.9890\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 643s 6s/step - loss: 0.0395 - accuracy: 0.9867 - val_loss: 0.0407 - val_accuracy: 0.9890\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 629s 6s/step - loss: 0.0370 - accuracy: 0.9883 - val_loss: 0.0349 - val_accuracy: 0.9890\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 3373s 33s/step - loss: 0.0380 - accuracy: 0.9874 - val_loss: 0.0339 - val_accuracy: 0.9890\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 4770s 47s/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.0346 - val_accuracy: 0.9902\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 4990s 49s/step - loss: 0.0326 - accuracy: 0.9901 - val_loss: 0.0353 - val_accuracy: 0.9902\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 4785s 47s/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0329 - val_accuracy: 0.9902\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 4120s 40s/step - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.0321 - val_accuracy: 0.9902\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 4692s 46s/step - loss: 0.0283 - accuracy: 0.9892 - val_loss: 0.0316 - val_accuracy: 0.9902\n"
     ]
    }
   ],
   "source": [
    "# compile model\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train head of the network\n",
    "H = model.fit(\n",
    "aug.flow(x_train, y_train, batch_size=BS),\n",
    "steps_per_epoch=len(x_train) // BS,\n",
    "validation_data=(x_test, y_test),\n",
    "validation_steps=len(x_test) // BS,\n",
    "epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0a10fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mask_detector.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89412fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm continuing the code after quite some time, so I'm going to load the model again\n",
    "\n",
    "t_model = load_model(\"mask_detector.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc7f3ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 49s 2s/step\n"
     ]
    }
   ],
   "source": [
    "predIdx = t_model.predict(x_test, BS)\n",
    "\n",
    "predIdx = np.argmax(predIdx, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "506c8d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.99      0.99      0.99       433\n",
      "without_mask       0.99      0.99      0.99       386\n",
      "\n",
      "    accuracy                           0.99       819\n",
      "   macro avg       0.99      0.99      0.99       819\n",
      "weighted avg       0.99      0.99      0.99       819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), predIdx, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184875b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
